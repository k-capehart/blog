[{"content":" Open source REST API wrapper written in Go.\nLanguage: Golang Allow Golang developers to easily call Salesforce REST API endpoints to authenticate to an org and manipulate data Utilizes go-soql, a package created by Salesforce for marshalling SOQL queries Batch requests together to insert, update, upsert, or delete large amounts of records with or without the Bulk API Composite Requests group multiple sub-requests into a single request ","date":null,"permalink":"/projects/go-salesforce/","section":"Projects","summary":"Open source REST API wrapper written in Go.","title":"Go-Salesforce"},{"content":" Open source custom Salesforce CLI plugin.\nLanguage: TypeScript Custom commands for the salesforce command line interface that can be installed as a plugin for anyone to use Display differences between a source tracked org and a local project Automatically generate Apex trigger frameworks based off of custom templates ","date":null,"permalink":"/projects/kc-sf-plugin/","section":"Projects","summary":"Open source custom Salesforce CLI plugin.","title":"SF CLI Plugin"},{"content":" Personal salesforce developer environment with custom automation.\nLanguage: Apex, Makefile A personal developer environment used for testing configuration and automation Makefile - Automated bash scripts for creating scratch orgs, generating components, and deploying to an org GitHub Actions - Automatically validate component files and run apex tests when a pull request is created, and deploy when a GitHub release is published Apex Trigger Framework - A forked version of a common trigger design pattern that standardizes common use cases for validation, applying default values to records, and bypassing logic ","date":null,"permalink":"/projects/salesforce-dev-org/","section":"Projects","summary":"Personal salesforce developer environment with custom automation.","title":"Salesforce Development Org"},{"content":"","date":null,"permalink":"/","section":"Kyle Capehart","summary":"","title":"Kyle Capehart"},{"content":" View Resume\n","date":null,"permalink":"/projects/","section":"Projects","summary":"View Resume","title":"Projects"},{"content":"","date":null,"permalink":"/tags/salesforce/","section":"Tags","summary":"","title":"Salesforce"},{"content":"","date":null,"permalink":"/tags/salesforce-org/","section":"Tags","summary":"","title":"Salesforce Org"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/tags/sf-cli/","section":"Tags","summary":"","title":"Sf Cli"},{"content":"","date":null,"permalink":"/tags/golang/","section":"Tags","summary":"","title":"Golang"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"Interact with your Salesforce org using Golang.\nIntroduction #go-salesforce is a new Salesforce REST API wrapper written in Go (golang), a statically typed, compiled programming language built by Google. It aims to make it easier for Go developers to call Salesforce REST API endpoints (such as authentication, querying, inserting/updating records, etc.) by wrapping these calls in methods that do all the hard work. Integrate an application into Salesforce with ease or utilize the power of Go by automating repetitive data tasks.\nCheck out the repository in GitHub: k-capehart/go-salesforce\nThe code is entirely open source, and was created as a fun side project to explore the Salesforce REST API and learn Go. Give the project a star and create an issue to start contributing.\nFeatures #Read the documentation for a full list of features and examples.\nSOQL Queries using go-soql #go-salesforce utilizes Salesforce\u0026rsquo;s very own go-soql package for marshalling structs into SOQL. Use soql struct tags to construct queries and pass it to the QueryStruct method. This avoids the need to separately maintain SOQL queries and structs, and guards against SOQL injection. The Query method is also available and accepts a string parameter for the query.\nRead more about go-soql: forcedotcom/go-soql\nWork with Batches of Records #Perform operations on collections of records. go-salesforce will split these records into batches and collect the results to be returned as errors if necessary. Insert, update, or delete large collections of records while avoiding Bulk API specific limits in your org. Set the batch size for full control on how Salesforce processes the data.\nRead about Salesforce API Limits, and Bulk API Limits.\nComposite Requests #Salesforce\u0026rsquo;s Composite API allows multiple \u0026ldquo;subrequests\u0026rdquo; to be contained within a single \u0026ldquo;composite request\u0026rdquo;, reducing the overall number of API calls. Up to 5000 records can be included in a single composite request. Datasets larger than 5000 will need to use either the Collection or Bulk methods.\nSalesforce also supports dependent subrequests. For example, you can Insert a new Account and multiple child records associated with the Account all within the same request. This is very powerful and will be built upon in go-salesforce.\nBulk API v2 #Create jobs to asynchronously insert, update, upsert, query, or delete large datasets. This can be done either through csv files or with runtime data. You can optionally wait for jobs to finish to process potential errors, or let it run in the background and fetch the results later.\nA common use case is to have predefined test data within a csv file that needs to be loaded into a Salesforce sandbox after a refresh. With go-salesforce you can automate this data loading process in just a few lines using the InsertBulkFile method.\nExample - Migrating Contacts #Steps are outlined below on how to create a simple go-salesforce utility to transfer Contacts from one Account to another. The program should:\nTake 2 inputs: a source Account Id and a target Account Id Query all the related Contacts for the given source Account Update these contacts to be related to the target Account Source code can be found here: k-capehart/go-salesforce-example\nPrerequisites:\nSalesforce Developer Edition org Basic knowledge of Salesforce and Golang 1. Create a Salesforce Connected App #This example will use the Client Credentials OAuth flow. Read official documentation on creating a Connected App for OAuth 2.0 Client Credentials Flow.\nIn your Salesforce Org, navigate to Setup and search for \u0026ldquo;App Manager\u0026rdquo;. Click on \u0026ldquo;New Connected App\u0026rdquo;.\nFill out the following details, using your own email or that of an admin.\nConnected App Name: Go Client Contact Email: [your own email] Enable OAuth Settings: TRUE Callback URL: https://[YOUR SF DOMAIN]/services/oauth2/token Selected OAuth Scopes: Manage user data via APIs (api) Enable Client Credentials Flow: TRUE Click \u0026ldquo;Save\u0026rdquo;, then click on \u0026ldquo;Manage\u0026rdquo; and \u0026ldquo;Edit Policies\u0026rdquo;. Under \u0026ldquo;Client Credentials Flow\u0026rdquo;, set the \u0026ldquo;Run As\u0026rdquo; user to the user that should be authenticated.\nClick \u0026ldquo;Save\u0026rdquo;, and then return to the View page of the Connected App in App Manager. Note down the Consumer Key and Consumer Secret by clicking on \u0026ldquo;Manage Consumer Details\u0026rdquo;.\n2. Create a new Go Module and connect to Salesforce #In a new directory, run the following command:\ngo mod init main\nTo install the latest version of go-salesforce, execute the following:\ngo get github.com/k-capehart/go-salesforce\nCreate a new file called: migrate_contacts.go. Within this file, paste the following code:\npackage main import ( \u0026#34;errors\u0026#34; \u0026#34;os\u0026#34; ) // TODO: Type Definitions func main() { args := os.Args if len(args) \u0026lt; 3 { panic(errors.New(\u0026#34;expected 2 command line arguments in addition to program name\u0026#34;)) } srcAccount := os.Args[1] targetAccount := os.Args[2] // TODO: Salesforce Authentication // TODO: Query Contacts // TODO: Update Contacts } This code uses the os package to read arguments from the command line. The first command (index 0) is always the program name. This expects 2 more arguments, which should be processed as Salesforce Account Ids.\nMore information on creating Go Modules.\nNext, replace // TODO: Salesforce Authentication with the following code:\nsf, err := salesforce.Init(salesforce.Creds{ Domain: {YOUR SALESFORCE DOMAIN}, ConsumerKey: {YOUR CONNECTED APP CONSUMER KEY}, ConsumerSecret: {YOUR CONNECTED APP CONSUMER SECRET}, }) if err != nil { panic(err) } This uses the Init method from go-salesforce to return a Salesforce instance using your client credentials from the previous step. Never publicly expose your ConsumerKey or Secret. Always securely store credentials outside of your codebase before committing to a repository.\n3. Query Contacts using go-soql #There are two options to query data using go-salesforce. One option would be to use the Query method to pass in a query as a string. However, Salesforce has created a package specifically for marshalling SOQL queries which will be utilized for this example. Read more about go-soql.\nReplace // TODO: Type Definitions with the following type definitions:\ntype Contact struct { Id string `soql:\u0026#34;selectColumn,fieldName=Id\u0026#34; json:\u0026#34;Id\u0026#34;` AccountId string `soql:\u0026#34;selectColumn,fieldName=AccountId\u0026#34; json:\u0026#34;AccountId\u0026#34;` } type ContactQueryCriteria struct { AccountId string `soql:\u0026#34;equalsOperator,fieldName=AccountId\u0026#34;` } type ContactSoqlQuery struct { SelectClause Contact `soql:\u0026#34;selectClause,tableName=Contact\u0026#34;` WhereClause ContactQueryCriteria `soql:\u0026#34;whereClause\u0026#34;` } Note the soql struct tags that inform go-soql how to transform these structs into queries.\nReplace // TODO: Query Contacts with this code:\ncontacts := []Contact{} contactSoqlQuery := ContactSoqlQuery{ SelectClause: Contact{}, WhereClause: ContactQueryCriteria{ AccountId: srcAccount, }, } err = sf.QueryStruct(contactSoqlQuery, \u0026amp;contacts) if err != nil { panic(err) } contactSoqlQuery represents a SOQL query that selects the Id and AccountId fields, with a filter for AccountId. The SELECT clause is simply the fields from the Contact struct. The result is then unmarshalled into a slice of type Contact. This is useful because you don\u0026rsquo;t have to separately maintain a query and a SObject type, since the fields are all pulled from the same definition.\n4. Update Contact records #Next, the program should process the contacts and update the AccountId field.\nReplace // TODO: Update Contacts with the last bit of code.\nfor i := range contacts { contacts[i].AccountId = targetAccount } logger := log.New(os.Stdout, \u0026#34;INFO: \u0026#34;, log.Ldate|log.Ltime) err = sf.UpdateCollection(\u0026#34;Contact\u0026#34;, contacts, 200) if err != nil { logger.Fatal(err.Error()) } else { logger.Print(\u0026#34;successfully updated \u0026#34; + strconv.Itoa(len(contacts)) + \u0026#34; contacts\u0026#34;) } This loops through the contacts variable that was populated from the query, and updates the AccountId value to be that of the target account. The list is then passed as an argument to the UpdateCollection method. The batch size is given as 200 but can be adjusted anywhere in the range of 1-200. If everything succeeds, then log how many Contacts were updated.\n5. Run the program #The final code should look like this, but with your own org credentials:\npackage main import ( \u0026#34;errors\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;github.com/k-capehart/go-salesforce\u0026#34; ) type Contact struct { Id string `soql:\u0026#34;selectColumn,fieldName=Id\u0026#34; json:\u0026#34;Id\u0026#34;` AccountId string `soql:\u0026#34;selectColumn,fieldName=AccountId\u0026#34; json:\u0026#34;AccountId\u0026#34;` } type ContactQueryCriteria struct { AccountId string `soql:\u0026#34;equalsOperator,fieldName=AccountId\u0026#34;` } type ContactSoqlQuery struct { SelectClause Contact `soql:\u0026#34;selectClause,tableName=Contact\u0026#34;` WhereClause ContactQueryCriteria `soql:\u0026#34;whereClause\u0026#34;` } func main() { args := os.Args if len(args) \u0026lt; 3 { panic(errors.New(\u0026#34;expected 2 command line arguments in addition to program\u0026#34;)) } srcAccount := os.Args[1] targetAccount := os.Args[2] sf, err := salesforce.Init(salesforce.Creds{ Domain: {YOUR SALESFORCE DOMAIN}, ConsumerKey: {YOUR CONNECTED APP CONSUMER KEY}, ConsumerSecret: {YOUR CONNECTED APP CONSUMER SECRET}, }) if err != nil { panic(err) } contacts := []Contact{} contactSoqlQuery := ContactSoqlQuery{ SelectClause: Contact{}, WhereClause: ContactQueryCriteria{ AccountId: srcAccount, }, } err = sf.QueryStruct(contactSoqlQuery, \u0026amp;contacts) if err != nil { panic(err) } for i := range contacts { contacts[i].AccountId = targetAccount } logger := log.New(os.Stdout, \u0026#34;INFO: \u0026#34;, log.Ldate|log.Ltime) err = sf.UpdateCollection(\u0026#34;Contact\u0026#34;, contacts, 200) if err != nil { logger.Fatal(err.Error()) } else { logger.Print(\u0026#34;successfully updated \u0026#34; + strconv.Itoa(len(contacts)) + \u0026#34; contacts\u0026#34;) } } Source code: k-capehart/go-salesforce-example\nNow that the code is complete, it can be executed. From the command line, build the package.\ngo build migrate_contacts.go\nRun the program, replacing the Salesforce IDs below with those of Account Ids in your Salesforce org. The first Id is the Account with Contacts that should migrate to the second Account.\n./migrate_contacts 001Dn000013hAraIAE 001Dn00000NTt34IAD\nComments or questions? Send me a message\n","date":"3 May 2024","permalink":"/posts/go-salesforce/","section":"Posts","summary":"Interact with your Salesforce org using Golang.","title":"Go-Salesforce: A Salesforce REST API wrapper written in Go"},{"content":"","date":null,"permalink":"/categories/salesforce/","section":"Categories","summary":"","title":"Salesforce"},{"content":"Streamline your Salesforce release pipeline.\nUsing the right tools #There are many tutorials that cover creating GitHub Actions for Salesforce. This article\u0026rsquo;s intention is to cover a few gaps and ensure release managers are using the best available tools.\nUse newer sf-cli over the deprecated sfdx-cli (announcement) Utilize new sfdx-url-stdin authorization method from sf-cli Release 2.24.4 (implemented by yours truly) Enforce release process with branch protections CI/CD in Salesforce #Continuous integration and continuous delivery/deployment (CI/CD) describes the process by which software development teams quickly develop and deploy applications. In the world of Salesforce, this means being able to automate testing and deployments from scratch orgs (and sandboxes) all the way up to production.\nGitHub Actions are a powerful way to automate CI/CD processes by triggering workflows based off of events (like opening a pull request) in a GitHub repository. Read more about GitHub Actions.\nThe sf-cli is Salesforce\u0026rsquo;s powerful new command line interface that supports running tests, deploying metadata, and more. Workflows can automatically run these commands so that developers don\u0026rsquo;t have to manually execute deployments. This helps enable source-driven development by designating version control as the source of truth.\nCreating a workflow using GitHub Actions #By the end of this tutorial you should have the following configurations to power your Salesforce releases:\nA workflow to validate metadata when a pull request is opened A workflow to deploy metadata when a release is created Branch protections to ensure code must be successfully validated before merged The source code used for this tutorial can be found here: https://github.com/k-capehart/sfdc-github-actions\nWhat you need #This article assumes that you have basic knowledge of Salesforce and working within a git repository. Here are a few prerequisites, all entirely free.\nSalesforce Developer Edition org GitHub account Salesforce Command Line Interface If you are using the old sfdx-cli, upgrade to the new sf-cli Visual Studio Code with Salesforce Extension Pack Learn how to setup your Salesforce Developer Environment in VS Code 1. Setup #This assumes that you already have a Salesforce project created and setup in Visual Studio Code. Review the prerequisites above if not. A fresh Salesforce project should look something like this in GitHub.\n2. SFDX Authorization URL #A GitHub workflow must be able to authenticate to an org in order to deploy metadata. In a production environment, a Service User should be used so that permissions are properly delineated.\nEnsure that you are authenticated to the target Salesforce org. sf org login web\nOnce connected, you will need the SFDX Authorization URL. sf org display --verbose\nThe output will display sensitive information regarding your Salesforce org. This should never be shared. Fortunately, GitHub provides a simple way to securely store tokens that can be accessed from workflows.\nFirst, copy the value for Sfdx Auth Url from the output of the previous command.\nIn your GitHub repository, go to \u0026ldquo;Settings\u0026rdquo; then \u0026ldquo;Secrets and variables\u0026rdquo; and \u0026ldquo;Actions\u0026rdquo;.\nClick on \u0026ldquo;New repository secret\u0026rdquo;. Note that Environment secrets can also be created to manage credentials for different Salesforce environments.\nName the secret SFDX_AUTH_URL, then paste the Sfdx Auth Url value from the output of sf org display --verbose into the secret. Then click \u0026ldquo;Add secret\u0026rdquo;.\n3. Create validation workflow #At the root of your VS Code project, create a directory and sub directory: .github/workflows/.\nWithin the new workflow/ directory create a new file: validate.yaml.\nYour folder structure in VS Code should now look something like this.\nPaste the following code into validate.yaml.\nname: Validate pull request on: pull_request: branches: - main types: [opened, synchronize] paths: - \u0026#39;force-app/**\u0026#39; jobs: validate-deployment: runs-on: ubuntu-latest container: image: salesforce/cli:latest-slim steps: - name: \u0026#39;Checkout source code\u0026#39; uses: actions/checkout@v4 with: fetch-depth: 0 - name: \u0026#39;Authenticate using SFDX_AUTH_URL\u0026#39; run: | echo ${{ secrets.SFDX_AUTH_URL }} | sf org login sfdx-url -s -u - name: \u0026#39;Validate\u0026#39; run: | sf project deploy validate -d force-app/ -l RunLocalTests -w 30 Let\u0026rsquo;s break this down.\nname: Validate pull request on: pull_request: branches: - main types: [opened, synchronize] paths: - \u0026#39;force-app/**\u0026#39; This names the workflow \u0026ldquo;Validate pull request\u0026rdquo; and defines it to be triggered on the following events:\na pull request is opened against the main branch a pull request against the main branch is updated to reflect new changes It also limits the detected changes to the force-app/ file path, which is where deployable metadata is located in a Salesforce project. That way validations aren\u0026rsquo;t triggered if an update is made to any other component, like the README.\njobs: validate-deployment: runs-on: ubuntu-latest container: image: salesforce/cli:latest-slim This creates a new job called validate deployment which runs in a Ubuntu virtual machine. The runner includes an image of the latest version of the salesforce/cli. This allows the job to execute sf commands.\nsteps: - name: \u0026#39;Checkout source code\u0026#39; uses: actions/checkout@v4 with: fetch-depth: 0 The first step within the job is to use an action to checkout the source code. This allows the workflow to access the files in the repository. fetch-depth: 0 lets it fetch the entire commit history.\n- name: \u0026#39;Authenticate using SFDX_AUTH_URL\u0026#39; run: | echo ${{ secrets.SFDX_AUTH_URL }} | sf org login sfdx-url -s -u Next, the workflow authenticates into the target environment.\necho ${{ secrets.SFDX_AUTH_URL }} | - access the SFDX_AUTH_URL secret and pipe it into the next command sf org login sfdx-url - authorize an org using a Salesforce DX authorization URL -s - set the org as the default that all org-related commands run against -u - indicates that the authorization URL will be piped in Read more about authentication using the SFDX Authorization URL.\n- name: \u0026#39;Validate\u0026#39; run: | sf project deploy validate -d force-app/ -l RunLocalTests -w 30 Finally, validate the metadata against the target environment.\nsf project deploy validate - validate a metadata deployment without actually executing it -d force-app/ - path to the source files to be deployed -l RunLocalTests - all tests in your org are run, except tests from packages -w 30 - wait 30 minutes to finish before displaying results 4. Create release workflow #Create a new file in .github/workflows/: release.yaml.\nPaste the following code into release.yaml.\nname: Deploy project on: release: types: [published] jobs: deploy-release: runs-on: ubuntu-latest container: image: salesforce/cli:latest-slim steps: - name: \u0026#39;Checkout source code\u0026#39; uses: actions/checkout@v3 with: fetch-depth: 0 - name: \u0026#39;Authenticate using SFDX_AUTH_URL\u0026#39; run: | echo ${{ secrets.SFDX_AUTH_URL }} | sf org login sfdx-url -s -u - name: \u0026#39;Deploy\u0026#39; run: | sf project deploy start -d force-app/ -l RunLocalTests -w 30 This is almost identical to validate.yaml but with a couple key differences.\nname: Deploy project on: release: types: [published] This names the workflow \u0026ldquo;Deploy project\u0026rdquo; and defines it to be triggered on the following event:\na release is published - name: \u0026#39;Deploy\u0026#39; run: | sf project deploy start -d force-app/ -l RunLocalTests -w 30 sf project deploy start - deploy metadata to an org from your local project -d force-app/ - path to the source files to be deployed -l RunLocalTests - all tests in your org are run, except from packages -w 30 - wait 30 minutes to finish before displaying results Once complete, push the workflows to your GitHub repository. git add . git commit -m \u0026quot;create new workflows for salesforce deployments\u0026quot; git push\n5. Testing the workflows #Open a pull request #In a real working environment, development might be done in a scratch org, then pushed to GitHub so that changes can be deployed to a shared sandbox. However, that isn\u0026rsquo;t strictly necessary for this tutorial.\nCheckout a new branch to hold your changes. git checkout -b test-workflows\nMake a simple change, like creating a blank Apex Class. sf apex generate class -n TestApexClass -d force-app/main/default/classes\nCommit your changes and push to the branch git add . git commit -m \u0026quot;test new github workflow\u0026quot; git push -u origin test-workflows\nIn GitHub, create a new Pull Request, merging the test-workflows branch with the main branch.\nYou should see the Validate job begin to run.\nOnce complete, the pull request can be merged.\nCreate a release #In your GitHub repository, click on \u0026ldquo;Releases\u0026rdquo;, then \u0026ldquo;Create a new release\u0026rdquo;.\nChoose a tag, generally a release number (such as 0.0.1), then click \u0026ldquo;Generate release notes\u0026rdquo;. Finally, click \u0026ldquo;Publish release\u0026rdquo;.\nThe release workflow is now running, and can be monitored under the \u0026ldquo;Actions\u0026rdquo; tab.\nOnce complete, the Apex class will have deployed to your Salesforce org.\n6. Setup branch protections #The workflows will now be available in your repository and will run whenever a pull request or release is created. However, validations work best when they are enforced. GitHub repositories can be setup with branch protections to ensure workflows pass before a pull request is merged.\nIn your GitHub repository, go to \u0026ldquo;Settings\u0026rdquo; then \u0026ldquo;Branches\u0026rdquo;. Then click \u0026ldquo;Add branch protection rule\u0026rdquo;.\nFill out the following:\nBranch name pattern: main Require a pull request before merging optional: Require approvals Require status checks to pass before merging Require branches to be up to date before merging validate-deployment Do not allow bypassing the above settings Finally, click \u0026ldquo;Create\u0026rdquo; to enable the new branch protections. GitHub now prevents commits being directly pushed to main, and Salesforce validations must successfully pass before a pull request can be merged.\nConclusion #View the source code\nSalesforce supports many options for automating deployments, and the right solution will depend on a variety of factors. GitHub Actions empower developers to quickly and efficiently spin up pipelines, so that everyone is always on the same page before a new release. Modifications to the workflow can easily be made to adapt to more complicated requirements. To enable deployments to multiple sandbox environments, look into GitHub Action environments.\nComments or questions? Send me a message\n","date":"2 April 2024","permalink":"/posts/github-actions/","section":"Posts","summary":"Streamline your Salesforce release pipeline.","title":"Automate your Salesforce Deployments with GitHub Actions"},{"content":"","date":null,"permalink":"/categories/dev-ops/","section":"Categories","summary":"","title":"Dev-Ops"},{"content":"","date":null,"permalink":"/categories/apex/","section":"Categories","summary":"","title":"Apex"},{"content":"","date":null,"permalink":"/categories/flows/","section":"Categories","summary":"","title":"Flows"},{"content":"Programmatic vs declarative solutions.\nApex vs Flows #It\u0026rsquo;s all been said before. Flows are the powerful, simple, declarative solution to automation in Salesforce that are getting better with every release.\nBut are they the right solution?\nIn most trainings, Flows are recommended as the go-to Salesforce tool, with Apex only used if the logic becomes too complex. Salesforce has even doubled down on their commitment to declarative tools by unveiling their new character, Flo the Flying Squirrel.\nHowever, flows were never meant to replace Apex entirely. They are simply an alternative solution to problems commonly solved using Apex triggers. There are times when Flows are a viable option, like if there isn’t a developer on hand who can write code. That being said, any software solution needs to be able to scale. For a company hoping to provide a smooth CRM transition, Salesforce implementations need to be designed by engineers from the start. Otherwise, it\u0026rsquo;s being set up for failure.\nThe Case for Apex #Engineers need to be allowed to engineer. This means using the best tools available, and Apex provides that. The reasoning is as follows.\nHandling Complex Logic #A small sales organization does not need much customization in Salesforce right away. Simple problems are easily solved by point-and-click tools. However, as time goes on and the organization grows, complexity compounds. Suddenly Salesforce needs to communicate with numerous external systems, process large batches of records, and perform complex SOQL queries, all of which Flows struggle to deliver.\nTake this example. There is a requirement to update a field on all child account records whenever a parent record is updated. A flow is created to satisfy this, which works at first. However, a few months later someone notices the flow occasionally fails. When a developer investigates, they discover a governor limit being hit when updating Accounts with thousands of child records. After spending time debugging, the logic is eventually moved to an Apex trigger which calls a helper class implementing the Database.Batchable interface.\nRecord updates like the example above should always be designed to handle bulk operations, best handled in Apex. Flows are often touted as easier to build, which is certainly true if you’re not a developer, but otherwise not necessarily. Valuable time can be wasted during a sprint trying to get a flow to handle a complex operation, only to eventually be abandoned and have the processing handled in an invocable Apex action. This extra development time can be avoided if the solution is designed in Apex from the start.\nEase of Maintenance #If too many processes are built in flows, then it quickly becomes difficult to maintain. Over time, flows might end up looking like this, which become a nightmare to debug:\nAs mentioned before, it might become necessary to move complex functionality from flows into code. If there are Apex triggers and record-triggered flows, then the order of execution needs to be considered to ensure expected outcomes still hold. With an absence of clear documentation, it can be cumbersome to figure out where certain business logic resides.\nIf a field is referenced in a deactivated flow version, it prevents deletion of the field, requiring old flow versions to be removed. This can prevent much needed refactoring, especially if an object is approaching the field limit. It’s also very tedious to move elements from one flow to another in the event anything needs to be reorganized.\nApex classes are easily designed to be reusable without significant development overhead. Refactoring code can be as simple as copying and pasting methods from a trigger into a helper class, so developers never have to waste time manually rewriting logic. Interfaces and abstract classes can be utilized to design well organized frameworks so that updates are always easy to make.\nTracking Changes #Version control is essential for any engineering team, Salesforce teams included. Flows have a versioning system, but it can be hard to determine exactly what has changed between each version. Luckily, flow metadata can be checked into a git repository and tracked from there.\nWhat’s the problem then?\nThe metadata is in XML, and not human readable. The only viable way to perform a code review on a flow is to open it in a sandbox and view it in the UI. This isn’t feasible if it was developed in a scratch org, meaning the reviewer will have to deploy it to their own environment. This extra step causes unneeded delays in development.\nApex offers a clear advantage due to its readability.\nTracking code in a git based repository is the industry standard, and is the best way to determine exactly what has changed between releases. Each modified line in an Apex class or trigger can easily be read by a reviewer and approved without any need of logging in to Salesforce. It is also a very familiar process for experienced software engineers.\nWriting Tests #Flows offer almost the same power as Apex but with a simpler learning curve, which is usually considered a positive. There’s a huge problem with this reasoning though. Apex code requires a minimum threshold of code coverage before deploying to production. Flows by default, do not.\nIf a tool can make external callouts to systems, reassign records, expose data, or any other number of high impact operations, there needs to be a certain level of security. Not to mention the reliability of a system that doesn\u0026rsquo;t have standardized tests in place. Declarative flow tests have recently been released, but they don’t replace the full functionality of Apex test classes. Most importantly, they\u0026rsquo;re missing the ability to automatically run during a deployment. This is essential in any CI/CD process to ensure breaking changes are caught.\nThere is a way to enforce flow test coverage from Apex tests, which is highly recommended for any organization using flows. However, the fact that it’s not enabled by default is a big concern. Salesforce themselves recommend a test-driven development process, which is best done through Apex tests to ensure they are created early on.\nCurrently there is no way to test asynchronous paths in flows, so it is hard to justify the use of them if automated tests can\u0026rsquo;t be created. Vote on this much needed feature in the Salesforce IdeaExchange.\nApex tests are flexible and easily written. They allow the ability to write bite-sized unit tests and create standardized data sets exclusively used for testing. Automated tests should always be used to reduce risk when new features are released. These test classes can be the difference between a successful launch and a catastrophic one.\nConclusion #Flows have their place in the Salesforce ecosystem, but when it comes to picking the right tool for the job, Apex comes out on top almost every time. Invest in developers early on and Salesforce is less likely to become bloated with poorly optimized solutions. Software engineering teams should be encouraged to embrace code rather than avoid it.\nComments or questions? Send me a message\n","date":"12 March 2024","permalink":"/posts/apex-over-flows/","section":"Posts","summary":"Programmatic vs declarative solutions.","title":"Why you should use Apex instead of Flows in Salesforce"},{"content":"","date":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":" I\u0026rsquo;m a Software Engineer based in Orlando, Florida who specializes in Salesforce implementations. I hold the Platform Developer II certification and earned my Computer Science degree at the University of Central Florida. I love to learn and am always seeking out new challenges.\nAt my current role I serve as a Senior Software Engineer at American Tire Distributors, where I work on various systems related to customer interaction. Previously, I worked as a Developer at Deloitte, giving me experience in a client facing role. I have acted as a leader throughout my career and always strive to nourish growth within my team.\nI am happiest when I am solving fun problems. This site aims to document my solutions and showcase work that I am proud of.\nBeyond work, I can usually be found reading a book, playing video games, or running. Ask me about my cat Brisket.\nView my Resume\n","date":null,"permalink":"/about/","section":"Kyle Capehart","summary":"I\u0026rsquo;m a Software Engineer based in Orlando, Florida who specializes in Salesforce implementations.","title":"About Me"}]